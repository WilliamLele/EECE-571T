{"cells":[{"cell_type":"markdown","source":["# EECE-571T - Assignment 2"],"metadata":{"id":"z0ffSZLoVp1F"}},{"cell_type":"markdown","source":["### Mount on Google Drive\n"],"metadata":{"id":"qV_f-VYWoFpy"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"id":"HQmqVUUZqbEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd gdrive/My Drive/EECE571T_Assignment2/"],"metadata":{"id":"Ha-dMtFxqfT-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"PpLqwKc9UjKl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7AAgEL2nHGg"},"outputs":[],"source":["import time\n","import numpy as np\n","import pandas as pd\n","import random\n","import matplotlib.pyplot as plt\n","\n","# import standard PyTorch modules\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# import torchvision module to handle image manipulation\n","import torchvision\n","import torchvision.transforms as transforms\n","print(\"Running on torch.__version__ = \", torch.__version__)\n","\n","torch.backends.cudnn.deterministic = True\n","\n","# utils\n","import os\n","from tqdm import tqdm\n","tqdm.pandas()\n","from collections import Counter"]},{"cell_type":"markdown","source":["### Helper Functions"],"metadata":{"id":"TUVmUx8PY4YA"}},{"cell_type":"code","source":["# a function to move tensors from the CPU to the GPU and vice versa\n","def dict_to_device(orig, device):\n","    new = {}\n","    for k,v in orig.items():\n","        new[k] = v.to(device)\n","    return new\n","\n","# a function to make gray-scale images the same shape as color images\n","def gray_to_color(x):\n","    return x.repeat(3, 1, 1)\n","\n","# a function to plot a batch of images together\n","def plot_images(img, ax):\n","    img = torchvision.utils.make_grid(img)\n","    npimg = img.numpy()\n","    ax.imshow(np.transpose(npimg, (1, 2, 0)))  "],"metadata":{"id":"de-TYlriY6ZE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q1"],"metadata":{"id":"riEkmtv8VtaX"}},{"cell_type":"markdown","source":["### Dataset and Dataloader"],"metadata":{"id":"ia3AtMLRU0Zz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGwIBAY3SYRy"},"outputs":[],"source":["# Use standard MNIST dataset\n","class MyDataset(torchvision.datasets.MNIST):    \n","    def __init__(self, *args, debug=False, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.debug = debug\n","    \n","    def __getitem__(self, idx):\n","        data = super().__getitem__(idx)\n","        img = data[0]\n","        label = data[1]\n","        return {'image': img, 'label': label}\n","    \n","    def __len__(self):\n","        return super().__len__()\n","\n","dataset = MyDataset(\n","    root = './',\n","    train = True,\n","    download = True,\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        gray_to_color,\n","    ]),\n","    debug=True,\n",")\n","\n","loader = torch.utils.data.DataLoader(dataset, batch_size=128, num_workers=0)"]},{"cell_type":"markdown","source":["### ToDo: train, validation, test split\n","\n","The standard MNIST dataset does not provide a validation set. Use 20% of the training data as the validation set.\n","\n","The standard MNIST dataset has a test set, and you can download it similar to downloading the train set, only by setting the train label to 'False'. Use the test set only for final the evaluation."],"metadata":{"id":"P0lazZkraP8M"}},{"cell_type":"code","source":["# ToDo: load the test set\n"],"metadata":{"id":"uJ5ZEChSWYFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: split the training data into train and validation, and define the dataloaders\n","train_loader = None\n","val_loader = None\n","test_loader = None"],"metadata":{"id":"noQlWs-Fbecq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: print the size of train, validation, and test sets\n"],"metadata":{"id":"TFgYOumlRZ8W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Network"],"metadata":{"id":"m-qcpHIZZsOY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rV9ktECSYRz"},"outputs":[],"source":["# an example of using available models in PyTorch\n","class MyResNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.resnet18 = torchvision.models.resnet18(num_classes=10)\n","    \n","    def forward(self, input_dict):        \n","        pred_label = self.resnet18(input_dict['image'])\n","        return {'label': pred_label}\n","\n","# a simple CNN model, implemented from the scratch\n","class MyNetwork(nn.Module):    \n","    def __init__(self):\n","        super(MyNetwork, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=1)        \n","        self.fc = nn.Linear(32*26*26, 10)\n","        \n","    def forward(self, input_dict):                 \n","        x = self.conv1(input_dict['image'])\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)        \n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        pred_label = nn.functional.log_softmax(x, dim=1)\n","\n","        return {'label': pred_label}\n","\n","# You can choose either of the defined networks, or define your own neural net\n","network = MyNetwork().to('cuda')\n","print(network)"]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"X82PEwzSZvXg"}},{"cell_type":"code","source":["# training loop\n","%matplotlib inline\n","from IPython import display\n","\n","# prepare plotting\n","fig = plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n","axes = fig.subplots(1,3)\n","\n","optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n","\n","num_epochs = 5\n","train_losses = []\n","val_losses = []\n","\n","for e in range(num_epochs):\n","    train_iter = iter(train_loader)\n","    network.train()\n","    for i in range(len(train_loader)):        \n","        batch_cpu = next(train_iter)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')\n","        pred = network(batch_gpu)\n","        pred_cpu = dict_to_device(pred, 'cpu')\n","        \n","        # calculate the loss and backward the gradient\n","        loss = nn.CrossEntropyLoss()(pred['label'], batch_gpu['label'])        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())           \n","\n","        if i%100==0:            \n","            axes[0].cla()\n","            axes[1].cla()            \n","\n","            # plot some sample image inputs\n","            plot_images(batch_cpu['image'][0:1], ax=axes[0])    \n","            axes[0].legend()\n","            axes[0].set_title('sample input')\n","\n","            # plot the training error on a log plot\n","            axes[1].plot(train_losses, label='loss')\n","            axes[1].set_yscale('log')\n","            axes[1].set_title('Training loss')\n","            axes[1].set_xlabel('number of gradient iterations')\n","            axes[1].legend()\n","\n","            # clear output window and diplay updated figure\n","            display.clear_output(wait=True)\n","            display.display(plt.gcf())\n","            print(\"Training epoch {}, iteration {} of {} ({} %), loss={}\".format(e, i, len(train_loader), 100*i//len(train_loader), train_losses[-1]))            \n","\n","    val_iter = iter(val_loader)\n","    network.eval()    \n","    for i in range(len(val_loader)):\n","        batch_cpu = next(val_iter)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')\n","        pred = network(batch_gpu)\n","        pred_cpu = dict_to_device(pred, 'cpu')\n","        \n","        # calculate the loss\n","        with torch.no_grad():\n","            loss = nn.CrossEntropyLoss()(pred['label'], batch_gpu['label'])        \n","            val_losses.append(loss.item()) \n","\n","        if i%10==0: \n","            axes[2].cla()            \n","\n","            # plot the validation error on a log plot\n","            axes[2].plot(val_losses, label='loss')\n","            axes[2].set_yscale('log')\n","            axes[2].set_title('Validation loss')\n","            axes[2].set_xlabel('number of gradient iterations')\n","            axes[2].legend()\n","\n","            # clear output window and diplay updated figure\n","            display.clear_output(wait=True)\n","            display.display(plt.gcf())\n","            print(\"Validation epoch {}, iteration {} of {} ({} %), loss={}\".format(e, i, len(val_loader), 100*i//len(val_loader), val_losses[-1]))            \n","plt.close('all')"],"metadata":{"id":"7K_GSHDCVUXB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ToDo: Evaluation\n","\n","Here we want to report the accuracy of the network's predictions. We have defined a function named 'get_accuracy' that returns the accuracy of the network on its input data.\n","\n","Here, we assumed that the network returns class probabilities as output. If your network returns class indices, you need to change this evaluation function as well.\n","\n","Print the accuracy of your network for the train, validation, and test sets."],"metadata":{"id":"bLWTsDFJWgbP"}},{"cell_type":"code","source":["def get_accuracy(network, data_loader):\n","    network.eval()\n","    iterator = iter(data_loader)    \n","    correct = 0\n","    total = 0\n","    for i in range(len(iterator)):        \n","        batch_cpu = next(iterator)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')        \n","        pred = network(batch_gpu)['label'].argmax(dim=1, keepdim=True)                                         \n","        correct += pred.eq(batch_gpu['label'].view_as(pred)).sum().item()        \n","        total += pred.shape[0]\n","           \n","    return correct / total"],"metadata":{"id":"XfxpL80cWgPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: report accuracy on train, validation, and test sets\n"],"metadata":{"id":"QpLmlfSMVTQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: Plot the input images and output of your network for a few samples in the test set\n"],"metadata":{"id":"PorIeQrxYBxo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q2"],"metadata":{"id":"OWduSu89XD1_"}},{"cell_type":"markdown","source":["### Dataset and Dataloader"],"metadata":{"id":"mOzcfTl5Y_K3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBL6xWU0Y_K7"},"outputs":[],"source":["# Use standard MNIST dataset\n","class AnomalyDataset(torch.utils.data.Dataset):\n","    def __init__(self, data):          \n","        self.data = data\n","        self.digits = {0:[], 1:[], 2:[], 3:[], 4:[]}        \n","        for idx in range(len(self.data)):    \n","            digit = self.data[idx][1]\n","            if digit in self.digits.keys():\n","                self.digits[digit].append(idx)        \n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):      \n","        norm, anomaly = random.sample(self.digits.keys(), k=2)\n","        anomaly_loc, = random.sample([0, 1, 2], k=1)\n","        norm1_idx, norm2_idx = random.sample(self.digits[norm], k=2)\n","        anomaly_idx, = random.sample(self.digits[anomaly], k=1)\n","        if anomaly_loc == 0:\n","            img0 = self.data[anomaly_idx][0]\n","            img1 = self.data[norm1_idx][0]\n","            img2 = self.data[norm2_idx][0]\n","        elif anomaly_loc == 1:\n","            img0 = self.data[norm1_idx][0]\n","            img1 = self.data[anomaly_idx][0]\n","            img2 = self.data[norm2_idx][0]\n","        elif anomaly_loc == 2:\n","            img0 = self.data[norm1_idx][0]\n","            img1 = self.data[norm2_idx][0]\n","            img2 = self.data[anomaly_idx][0]          \n","\n","        return {'img0': img0, 'img1': img1, 'img2': img2, 'index': anomaly_loc}        \n","\n","dataset = AnomalyDataset(torchvision.datasets.MNIST(\n","    root = './',\n","    train = True,\n","    download = True,\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        gray_to_color,\n","    ])\n","))\n","\n","loader = torch.utils.data.DataLoader(dataset, batch_size=128, num_workers=0)"]},{"cell_type":"code","source":["print('Selected digits and their frequencies:')\n","for key, value in loader.dataset.digits.items():\n","    print(key, len(value))"],"metadata":{"id":"ozpjw8-ccVje"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ToDo: train, validation, test split\n","\n","Use 20% of the training data as the validation set.\n","\n","The standard MNIST dataset has a test set, and you can download it similar to downloading the train set, only by setting the train label to 'False'. Use the test set only for final the evaluation."],"metadata":{"id":"spH6m-qn1TSZ"}},{"cell_type":"code","source":["# ToDo: load the test set\n"],"metadata":{"id":"7ffVjsnYcBYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: define the dataloaders\n","train_loader = None\n","val_loader = None\n","test_loader = None"],"metadata":{"id":"9uZIh9v61TSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: print the size of train, validation, and test sets\n"],"metadata":{"id":"0dx5H2Z7SY1H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ToDo: Network\n","\n","Implement a neural network that takes three images as input and returns the index of the image with the different digit.\n","\n","Your network should take a python dictionary as input and extract the input images from it. Your network should return a python dictionaly containing a key named 'index'."],"metadata":{"id":"7wYMpiDnsfLI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ey8RaNhWsfLO"},"outputs":[],"source":["# ToDo: Implement your neural network from scratch\n","class MyNetwork(nn.Module):    \n","    def __init__(self):\n","        super(MyNetwork, self).__init__()\n","\n","        # ToDo: code here\n","        \n","        \n","    def forward(self, input_dict):                         \n","        img0 = input_dict['img0']        \n","        img1 = input_dict['img1']\n","        img2 = input_dict['img2']\n","        \n","        # ToDo: code here\n","\n","        # Hint: use padding in conv layers to adjust the dimensions\n","        # Hint: max-pooling and ReLU layers can be useful\n","        # Hint: choose a suitable activation function for the last layer \n","        \n","\n","        return {'index': pred_index}\n","\n","network = MyNetwork().to('cuda')\n","print(network)"]},{"cell_type":"markdown","source":["### ToDo: Training"],"metadata":{"id":"tXtc6rhhtwGC"}},{"cell_type":"code","source":["# ToDo: define a suitable loss function \n","def my_loss_function(predicted_index, target_index):\n","\n","  # code here\n","\n","  return loss "],"metadata":{"id":"li1mo8YCUeif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training loop\n","%matplotlib inline\n","from IPython import display\n","\n","# prepare plotting\n","fig = plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n","axes = fig.subplots(1,3)\n","\n","optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n","\n","num_epochs = 5\n","train_losses = []\n","val_losses = []\n","\n","for e in range(num_epochs):\n","    train_iter = iter(train_loader)\n","    network.train()\n","    for i in range(len(train_loader)):        \n","        batch_cpu = next(train_iter)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')\n","        pred = network(batch_gpu)\n","        pred_cpu = dict_to_device(pred, 'cpu')\n","        \n","        # calculate the loss and backward the gradient\n","        loss = my_loss_function(pred['index'], batch_gpu['index'])        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())           \n","\n","        if i%100==0:            \n","            axes[0].cla()\n","            axes[1].cla()            \n","\n","            # plot some sample image inputs            \n","            plot_images(torch.cat((batch_cpu['img0'][0:1], batch_cpu['img1'][0:1], batch_cpu['img2'][0:1]), 0), ax=axes[0])    \n","            axes[0].legend()\n","            axes[0].set_title('sample input')\n","\n","            # plot the training error on a log plot\n","            axes[1].plot(train_losses, label='loss')\n","            axes[1].set_yscale('log')\n","            axes[1].set_title('Training loss')\n","            axes[1].set_xlabel('number of gradient iterations')\n","            axes[1].legend()\n","\n","            # clear output window and diplay updated figure\n","            display.clear_output(wait=True)\n","            display.display(plt.gcf())\n","            print(\"Training epoch {}, iteration {} of {} ({} %), loss={}\".format(e, i, len(train_loader), 100*i//len(train_loader), train_losses[-1]))            \n","\n","    val_iter = iter(val_loader)\n","    network.eval()    \n","    for i in range(len(val_loader)):\n","        batch_cpu = next(val_iter)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')\n","        pred = network(batch_gpu)\n","        pred_cpu = dict_to_device(pred, 'cpu')\n","        \n","        # calculate the loss\n","        with torch.no_grad():\n","            loss = my_loss_function(pred['index'], batch_gpu['index'])        \n","            val_losses.append(loss.item()) \n","\n","        if i%10==0: \n","            axes[2].cla()            \n","\n","            # plot the validation error on a log plot\n","            axes[2].plot(val_losses, label='loss')\n","            axes[2].set_yscale('log')\n","            axes[2].set_title('Validation loss')\n","            axes[2].set_xlabel('number of gradient iterations')\n","            axes[2].legend()\n","\n","            # clear output window and diplay updated figure\n","            display.clear_output(wait=True)\n","            display.display(plt.gcf())\n","            print(\"Validation epoch {}, iteration {} of {} ({} %), loss={}\".format(e, i, len(val_loader), 100*i//len(val_loader), val_losses[-1]))            \n","plt.close('all')"],"metadata":{"id":"Oz7ycBagtwGD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ToDo: Evaluation\n","\n","Here we want to report the accuracy of the network's predictions. We have defined a function named 'get_accuracy' that returns the accuracy of the network on its input data.\n","\n","Here, we assumed that the network returns class probabilities as output. If your network returns class indices, you need to change this evaluation function as well.\n","\n","Print the accuracy of your network for the train, validation, and test sets."],"metadata":{"id":"FZgyhGeBym3C"}},{"cell_type":"code","source":["def get_accuracy(network, data_loader):\n","    network.eval()\n","    iterator = iter(data_loader)    \n","    correct = 0\n","    total = 0\n","    for i in range(len(iterator)):        \n","        batch_cpu = next(iterator)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')        \n","        pred = network(batch_gpu)['index'].argmax(dim=1, keepdim=True)                                         \n","        correct += pred.eq(batch_gpu['index'].view_as(pred)).sum().item()        \n","        total += pred.shape[0]\n","           \n","    return correct / total"],"metadata":{"id":"hK6tKCwKym3M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: report accuracy on train, validation, and test sets\n"],"metadata":{"id":"y3awYYf41IJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: Plot the input images and output of your network for a few samples in the test set\n"],"metadata":{"id":"0TZ_ZGTTzEfe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q3"],"metadata":{"id":"GwAZBm99hfSk"}},{"cell_type":"markdown","source":["### Load and Tokenize Data"],"metadata":{"id":"M516Ld3Lfnm9"}},{"cell_type":"code","source":["data = pd.read_csv('./imdb_processed.csv')\n","data.head()"],"metadata":{"id":"TK_xBX9jbi_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# obtain list of words\n","words = ' '.join(data.processed.values).split()\n","\n","# check our list\n","words[30:40]"],"metadata":{"id":"YQ5YSgrjbjDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# build vocabulary\n","counter = Counter(words)\n","vocab = sorted(counter, key=counter.get, reverse=True)\n","token2word = dict(enumerate(vocab, 1))\n","token2word[0] = '<PAD>'\n","word2token = {word: id for id, word in token2word.items()}"],"metadata":{"id":"pvHO-JBcf_ZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenize reviews\n","reviews = data.processed.values\n","reviews_tokenized = [[word2token[word] for word in review.split()] for review in tqdm(reviews)]\n","\n","# padding sequences\n","def pad_features(reviews, pad_id, seq_length):    \n","    features = np.full((len(reviews), seq_length), pad_id, dtype=int)\n","    for i, row in enumerate(reviews):        \n","        features[i, :len(row)] = np.array(row)[:seq_length]\n","\n","    return features\n","\n","features = pad_features(reviews_tokenized, pad_id=word2token['<PAD>'], seq_length=256)\n","\n","print('number of reviews:', len(reviews_tokenized))\n","print('seq_length:', len(features[0]))\n","\n","# print first-5 words of first 3 reviews\n","print('\\n first-five words of the first-three reviews:')\n","print('===============')\n","features[:3, :5]"],"metadata":{"id":"KmutxG8If_be"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataloader"],"metadata":{"id":"10gym2O8k4Jr"}},{"cell_type":"code","source":["# we use 70%, 15%, 15% for train, validation, and test sets\n","train_size = .7     \n","val_size = .5\n","labels = data.label.to_numpy()       \n","\n","# make train set\n","split_id = int(len(features) * train_size)\n","train_x, remain_x = features[:split_id], features[split_id:]\n","train_y, remain_y = labels[:split_id], labels[split_id:]\n","\n","# make val and test set\n","split_val_id = int(len(remain_x) * val_size)\n","val_x, test_x = remain_x[:split_val_id], remain_x[split_val_id:]\n","val_y, test_y = remain_y[:split_val_id], remain_y[split_val_id:]\n","\n","# print out the shape\n","print('Train set: {}'.format(train_x.shape))\n","print('Validation set: {}'.format(val_x.shape))\n","print('Test set: {}'.format(test_x.shape))"],"metadata":{"id":"fUtpw4oSjwOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, reviews, labels):                  \n","        self.data = torch.utils.data.TensorDataset(torch.from_numpy(reviews), torch.from_numpy(labels).float())        \n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):                                \n","        review = self.data[index][0]\n","        label = self.data[index][1]\n","\n","        return {'review': review, 'label': label}        \n","\n","\n","train_set = MyDataset(train_x, train_y)\n","val_set = MyDataset(val_x, val_y)\n","test_set = MyDataset(test_x, test_y)\n","\n","train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=128)\n","val_loader = torch.utils.data.DataLoader(val_set, shuffle=True, batch_size=128)\n","test_loader = torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=128)"],"metadata":{"id":"XPqwDm8dsqle"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ToDo: Network\n","\n","Implement a neural network based on Long short-term memory (LSTM) that takes a series of words (a review) as input and returns the label of the review indicating whether it is positive (1) or negative (0).\n","\n","Your network should take a python dictionary as input and extract the input sentences from it. Your network should return a python dictionaly containing a key named 'label'."],"metadata":{"id":"fKcwr-Z7lwyM"}},{"cell_type":"code","source":["# ToDo: Implement your neural network \n","class SentimentLSTM(nn.Module):\n","    def __init__(self):\n","        super(SentimentLSTM, self).__init__()\n","\n","        # ToDo: code here\n","\n","        # Hint: start with an embedding layer\n","        # Hint: using dropout might be useful       \n","        # Hint: choose a suitable activation function for the last layer \n","        \n","\n","    def forward(self, input_dict):              \n","        x = input_dict['review'] \n","        \n","        # ToDo: code here\n","\n","        return {'label': pred_label}\n","\n","network = SentimentLSTM().to('cuda')\n","print(network)"],"metadata":{"id":"J4SS_pxBjwTt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ToDo: Training"],"metadata":{"id":"uAl8aDrZq5yo"}},{"cell_type":"code","source":["# ToDo: define a suitable loss function \n","def my_loss_function(predicted_label, target_label):\n","\n","  # code here\n","\n","  return loss "],"metadata":{"id":"aywwSvIWaNXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training loop\n","%matplotlib inline\n","from IPython import display\n","\n","# prepare plotting\n","fig = plt.figure(figsize=(20, 5), dpi= 80, facecolor='w', edgecolor='k')\n","axes = fig.subplots(1,2)\n","\n","optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n","\n","num_epochs = 10\n","train_losses = []\n","val_losses = []\n","\n","for e in range(num_epochs):\n","    train_iter = iter(train_loader)\n","    network.train()\n","    for i in range(len(train_loader)):        \n","        batch_cpu = next(train_iter)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')\n","        pred = network(batch_gpu)\n","        pred_cpu = dict_to_device(pred, 'cpu')\n","        \n","        # calculate the loss and backward the gradient        \n","        loss = my_loss_function(pred['label'], batch_gpu['label'])        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())           \n","\n","        if i%100==0:            \n","            axes[0].cla()                        \n","\n","            # plot the training error on a log plot\n","            axes[0].plot(train_losses, label='loss')\n","            axes[0].set_yscale('log')\n","            axes[0].set_title('Training loss')\n","            axes[0].set_xlabel('number of gradient iterations')\n","            axes[0].legend()\n","\n","            # clear output window and diplay updated figure\n","            display.clear_output(wait=True)\n","            display.display(plt.gcf())\n","            print(\"Training epoch {}, iteration {} of {} ({} %), loss={}\".format(e, i, len(train_loader), 100*i//len(train_loader), train_losses[-1]))            \n","\n","    val_iter = iter(val_loader)\n","    network.eval()    \n","    for i in range(len(val_loader)):\n","        batch_cpu = next(val_iter)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')\n","        pred = network(batch_gpu)\n","        pred_cpu = dict_to_device(pred, 'cpu')\n","        \n","        # calculate the loss\n","        with torch.no_grad():\n","            loss = my_loss_function(pred['label'], batch_gpu['label'])        \n","            val_losses.append(loss.item()) \n","\n","        if i%10==0: \n","            axes[1].cla()            \n","\n","            # plot the validation error on a log plot\n","            axes[1].plot(val_losses, label='loss')\n","            axes[1].set_yscale('log')\n","            axes[1].set_title('Validation loss')\n","            axes[1].set_xlabel('number of gradient iterations')\n","            axes[1].legend()\n","\n","            # clear output window and diplay updated figure\n","            display.clear_output(wait=True)\n","            display.display(plt.gcf())\n","            print(\"Validation epoch {}, iteration {} of {} ({} %), loss={}\".format(e, i, len(val_loader), 100*i//len(val_loader), val_losses[-1]))            \n","plt.close('all')"],"metadata":{"id":"6Y2ytRQVq6KJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ToDo: Evaluation\n","\n","Here we want to report the accuracy of the network's predictions. We have defined a function named 'get_accuracy' that returns the accuracy of the network on its input data.\n","\n","Here, we assumed that the network returns class probabilities as output. If your network returns class indices, you might need to change this evaluation function as well.\n","\n","Print the accuracy of your network for the train, validation, and test sets."],"metadata":{"id":"PGSVFB0g4UJo"}},{"cell_type":"code","source":["def get_accuracy(network, data_loader):\n","    network.eval()\n","    iterator = iter(data_loader)    \n","    correct = 0\n","    total = 0\n","    for i in range(len(iterator)):        \n","        batch_cpu = next(iterator)\n","        batch_gpu = dict_to_device(batch_cpu, 'cuda')        \n","        pred = network(batch_gpu)['label']\n","        binary_pred = torch.where(pred < 0.5, 0, 1).squeeze(-1)\n","        correct += binary_pred.eq(batch_gpu['label']).sum().item()        \n","        total += binary_pred.shape[0]\n","           \n","    return correct / total"],"metadata":{"id":"oyRNmKET4UJt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: report accuracy on train, validation, and test sets\n"],"metadata":{"id":"MmHOEPBc4UJt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ToDo: print the input review and output of your network for one positive \n","#       example and one negative example in the test set\n"],"metadata":{"id":"hXbG8MEo4UJt"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"provenance":[],"toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}